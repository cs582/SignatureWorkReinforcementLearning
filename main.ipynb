{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from models.q_training import train\n",
    "\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='log.txt',\n",
    "    format='%(levelname)s %(asctime)s: %(name)s - %(message)s ',\n",
    "    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    prog='DQN Trainer',\n",
    "    description='DQN Training algorithm for Portfolio Management',\n",
    "    epilog='Source code for Carlos Gustavo Salas Flores Signature Work at Duke University & Duke Kunshan University '\n",
    "           'for the B.S. in Data Science undergrduate degree. '\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(\"main\")\n",
    "\n",
    "model =\"Single_DQN\"\n",
    "reward ='roi'\n",
    "\n",
    "portfolio = 1\n",
    "\n",
    "episodes = 1000\n",
    "e = 0.01\n",
    "g = 0.8\n",
    "lr = 1e-4\n",
    "m = 0.001\n",
    "\n",
    "tr = 4\n",
    "d = 1000\n",
    "\n",
    "ic = 100000\n",
    "bl = 100000\n",
    "sl = 100000\n",
    "\n",
    "tp = 2\n",
    "gl = 21000\n",
    "\n",
    "batch = 128\n",
    "memory = 10000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_file = \"data/raw//ClosePriceData_2022-10-01_to_2022-08-21.csv\"\n",
    "portfolios_json = \"portfolios//portfolios.json\"\n",
    "\n",
    "portfolio = portfolio\n",
    "\n",
    "save_path = \"models/saved_models\"\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else None\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "model_name = model\n",
    "reward_metric = reward\n",
    "\n",
    "episodes = episodes\n",
    "epsilon = e\n",
    "gamma = g\n",
    "lr = lr\n",
    "momentum = m\n",
    "\n",
    "n_transactions = tr\n",
    "n_trading_days = d\n",
    "\n",
    "initial_cash = ic\n",
    "buy_limit = bl\n",
    "sell_limit = sl\n",
    "\n",
    "priority_fee = tp\n",
    "gas_limit = gl\n",
    "\n",
    "batch_size = batch\n",
    "memory_size = memory\n",
    "\n",
    "training_info = f\"\"\"\n",
    "    Training {model_name} in portfolio {portfolio} with\n",
    "        data_file = {data_file}\n",
    "        portfolios_json = {portfolios_json}\n",
    "\n",
    "        device = {\"CPU\" if not torch.cuda.is_available() else torch.cuda.get_device_name(device=device)}\n",
    "        loss_function = {loss_function}\n",
    "        reward_metric = {reward_metric}\n",
    "\n",
    "        episodes = {episodes}\n",
    "        epsilon = {epsilon}\n",
    "        gamma = {gamma}\n",
    "        lr = {lr}\n",
    "        momentum = {momentum}\n",
    "\n",
    "        n_transactions = {n_transactions}\n",
    "        n_trading_days = {n_trading_days}\n",
    "\n",
    "        initial_cash = {initial_cash}\n",
    "        buy_limit = {buy_limit}\n",
    "        sell_limit = {sell_limit}\n",
    "\n",
    "        priority_fee = {priority_fee}\n",
    "        gas_limit = {gas_limit}\n",
    "\n",
    "        batch_size = {batch_size}\n",
    "        memory_size = {memory_size}\n",
    "    \"\"\"\n",
    "print(training_info)\n",
    "\n",
    "logger.info(training_info)\n",
    "\n",
    "q, history_dqn = train(\n",
    "    model_name=model_name,\n",
    "    token_prices_address=data_file,\n",
    "    save_path=save_path,\n",
    "    portfolio_json=portfolios_json,\n",
    "    portfolio_to_use=portfolio,\n",
    "    initial_cash=initial_cash,\n",
    "    n_trading_days=n_trading_days,\n",
    "    n_tokens=None,\n",
    "    n_transactions=n_transactions,\n",
    "    buy_limit=buy_limit,\n",
    "    sell_limit=sell_limit,\n",
    "    priority_fee=priority_fee,\n",
    "    gas_limit=gas_limit,\n",
    "    loss_function=loss_function,\n",
    "    episodes=episodes,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    momentum=momentum,\n",
    "    memory_size=memory_size,\n",
    "    epsilon=epsilon,\n",
    "    gamma=gamma,\n",
    "    device=device,\n",
    "    reward_metric=reward_metric,\n",
    ")\n",
    "\n",
    "logger.info(\"Training Complete!\")\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "plt.title(\"Total reward history\")\n",
    "plt.plot(history_dqn[\"metric_history\"], color=\"red\")\n",
    "plt.savefig(f\"data/figures/{model_name}_reward_{current_time}.png\")\n",
    "\n",
    "plt.title(\"Total average loss\")\n",
    "plt.plot(history_dqn[\"avg_loss\"], color=\"blue\")\n",
    "plt.savefig(f\"data/figures/{model_name}_loss_{current_time}.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}